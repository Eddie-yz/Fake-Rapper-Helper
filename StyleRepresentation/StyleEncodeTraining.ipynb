{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchaudio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from model import SingleExtractor\n",
    "from loss import TripletLoss\n",
    "from dataPrep import MTATDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MTATDataset(pos_dir='../Data/spectrogram_pos',\\\n",
    "                            neg_dir='../Data/spectrogram_pos',\\\n",
    "                            negative_sample_size=4)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, dataloader, negative_sample_size=4, n_epochs=500, loss_mode='cosine', device='cpu'):\n",
    "        self.model = SingleExtractor(conv_channels=128,\n",
    "                                     sample_rate=16000,\n",
    "                                     n_fft=513,\n",
    "                                     n_harmonic=6,\n",
    "                                     semitone_scale=2,\n",
    "                                     learn_bw='only_Q').to(device)\n",
    "        self.device = device\n",
    "        self.negative_sample_size = negative_sample_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.criterion = TripletLoss(mode=loss_mode).to(self.device)\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "        self.current_optimizer = 'adam'\n",
    "        self.drop_counter = 0\n",
    "        self.trianing_loss = []\n",
    "        self.best_train_loss = 100\n",
    "        self.model_save_path = 'checkpoints'\n",
    "        self.dataloader = dataloader\n",
    "         \n",
    "    def optimizerScheduler(self):\n",
    "        # Adam to sgd\n",
    "        if self.current_optimizer == 'adam' and self.drop_counter == 60:\n",
    "            self.optimizer = SGD(self.model.parameters(), 1e-3, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "            self.current_optimizer = 'sgd_1'\n",
    "            self.drop_counter = 0\n",
    "            print('sgd 1e-3')\n",
    "        # First drop\n",
    "        elif self.current_optimizer == 'sgd_1' and self.drop_counter == 20:\n",
    "            for pg in self.optimizer.param_groups:\n",
    "                pg['lr'] = 1e-4\n",
    "            self.current_optimizer = 'sgd_2'\n",
    "            self.drop_counter = 0\n",
    "            print('sgd 1e-4')\n",
    "        # Second drop\n",
    "        elif self.current_optimizer == 'sgd_2' and self.drop_counter == 20:\n",
    "            for pg in self.optimizer.param_groups:\n",
    "                pg['lr'] = 1e-5\n",
    "            self.current_optimizer = 'sgd_3'\n",
    "            print('sgd 1e-5')\n",
    "\n",
    "            \n",
    "    def train(self):\n",
    "        t0 = time.time()\n",
    "        for epoch in range(self.n_epochs):\n",
    "            self.drop_counter += 1\n",
    "            self.model.train()\n",
    "            epoch_loss = []\n",
    "            for i, (anchor, pos, negs) in enumerate(self.dataloader):\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                anchor = Variable(anchor).to(self.device)\n",
    "                pos = Variable(pos).to(self.device)\n",
    "                # shape: (1, negative_sample_size, x, x) => (negative_sample_size, x, x)\n",
    "                # cannot handle when batch_size is not 1\n",
    "                negs = negs.squeeze(0)\n",
    "                negs = Variable(negs).to(self.device)\n",
    "                \n",
    "                # Feed tensors into the Siamese harmonic network\n",
    "                ha = self.model(anchor)\n",
    "                hp = self.model(pos)\n",
    "                hn = self.model(negs)\n",
    "                \n",
    "                # Compute triplet loss\n",
    "                loss = self.criterion(ha, hp, hn)\n",
    "                epoch_loss.append(loss.item())\n",
    "                \n",
    "                print (loss.item())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                if epoch_loss[-1] < self.best_train_loss:\n",
    "                    self.best_train_loss = epoch_loss[-1]\n",
    "                    torch.save(self.model.state_dict(),\\\n",
    "                               os.path.join(self.model_save_path, f'best_training_model_epoch{epoch}_iter{i}.pth'))\n",
    "                    \n",
    "            self.trianing_loss.append(np.mean(epoch_loss))\n",
    "            self.optimizerScheduler()\n",
    "            \n",
    "        print (\"Epoch: {:3d} | Train loss: {:.3f} | Time: {:4d}s\".format(epoch, self.trianing_loss[-1], time.time()-t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "styEncTrain = Trainer(dataloader=train_dataloader, device=torch.device(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print (next(styEncTrain.model.hstft.parameters()).is_cuda)\n",
    "print (next(styEncTrain.model.hstft_bn.parameters()).is_cuda)\n",
    "print (next(styEncTrain.model.conv_2d.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3988354802131653\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function AddBackward0 returned an invalid gradient at index 0 - expected type TensorOptions(dtype=float, device=cuda:0, layout=Strided, requires_grad=false) but got TensorOptions(dtype=float, device=cpu, layout=Strided, requires_grad=false) (validate_outputs at /pytorch/torch/csrc/autograd/engine.cpp:484)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f9324400536 in /datasets/home/59/959/yiz086/.local/lib/python3.7/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x2d84224 (0x7f92fffe8224 in /datasets/home/59/959/yiz086/.local/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #2: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x548 (0x7f92fffe9d58 in /datasets/home/59/959/yiz086/.local/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f92fffebce2 in /datasets/home/59/959/yiz086/.local/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f92fffe4359 in /datasets/home/59/959/yiz086/.local/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f931362ecf8 in /datasets/home/59/959/yiz086/.local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #6: <unknown function> + 0xc819d (0x7f932df9e19d in /opt/conda/lib/python3.7/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6)\nframe #7: <unknown function> + 0x76db (0x7f933093a6db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #8: clone + 0x3f (0x7f933066388f in /lib/x86_64-linux-gnu/libc.so.6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e7ad2009a6cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstyEncTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-c789b0add146>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function AddBackward0 returned an invalid gradient at index 0 - expected type TensorOptions(dtype=float, device=cuda:0, layout=Strided, requires_grad=false) but got TensorOptions(dtype=float, device=cpu, layout=Strided, requires_grad=false) (validate_outputs at /pytorch/torch/csrc/autograd/engine.cpp:484)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f9324400536 in /datasets/home/59/959/yiz086/.local/lib/python3.7/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x2d84224 (0x7f92fffe8224 in /datasets/home/59/959/yiz086/.local/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #2: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x548 (0x7f92fffe9d58 in /datasets/home/59/959/yiz086/.local/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f92fffebce2 in /datasets/home/59/959/yiz086/.local/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f92fffe4359 in /datasets/home/59/959/yiz086/.local/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f931362ecf8 in /datasets/home/59/959/yiz086/.local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #6: <unknown function> + 0xc819d (0x7f932df9e19d in /opt/conda/lib/python3.7/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6)\nframe #7: <unknown function> + 0x76db (0x7f933093a6db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #8: clone + 0x3f (0x7f933066388f in /lib/x86_64-linux-gnu/libc.so.6)\n"
     ]
    }
   ],
   "source": [
    "styEncTrain.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/best_training_model_epoch2_iter30.pth'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join('checkpoints', f'best_training_model_epoch{2}_iter{30}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
