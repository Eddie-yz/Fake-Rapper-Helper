{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "import librosa\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from numpy.random import randint\n",
    "import os\n",
    "from os import listdir\n",
    "from os import path\n",
    "from torch.utils.data import Dataset\n",
    "    \n",
    "# deepspeech   \n",
    "def load_audio(path, audiotime):\n",
    "    sample_rate, sound = read(path)\n",
    "    sound = sound.astype('float32') / 32767  # normalize audio\n",
    "    if len(sound.shape) > 1:\n",
    "        if sound.shape[1] == 1:\n",
    "            sound = sound.squeeze()\n",
    "        else:\n",
    "            sound = sound.mean(axis=1)  # multiple channels, average\n",
    "    selection = len(sound)-sample_rate*audiotime\n",
    "    position = randint(0,selection)\n",
    "    time = position/sample_rate\n",
    "    sound = sound[position: position+sample_rate*audiotime ]\n",
    "    return sound, time\n",
    "\n",
    "def augment_audio_with_sox(path, sample_rate, tempo, gain):\n",
    "    \"\"\"\n",
    "    Changes tempo and gain of the recording with sox and loads it.\n",
    "    \"\"\"\n",
    "    with NamedTemporaryFile(suffix=\".wav\") as augmented_file:\n",
    "        augmented_filename = augmented_file.name\n",
    "        sox_augment_params = [\"tempo\", \"{:.3f}\".format(tempo), \"gain\", \"{:.3f}\".format(gain)]\n",
    "        sox_params = \"sox \\\"{}\\\" -r {} -c 1 -b 16 -e si {} {} >/dev/null 2>&1\".format(path, sample_rate,\n",
    "                                                                                      augmented_filename,\n",
    "                                                                                      \" \".join(sox_augment_params))\n",
    "        os.system(sox_params)\n",
    "        y,_ = load_audio(augmented_filename)\n",
    "        return y\n",
    "\n",
    "\n",
    "def load_randomly_augmented_audio(path, sample_rate=16000, tempo_range=(0.85, 1.15),\n",
    "                                  gain_range=(-6, 8)):\n",
    "    \"\"\"\n",
    "    Picks tempo and gain uniformly, applies it to the utterance by using sox utility.\n",
    "    Returns the augmented utterance.\n",
    "    \"\"\"\n",
    "    low_tempo, high_tempo = tempo_range\n",
    "    tempo_value = np.random.uniform(low=low_tempo, high=high_tempo)\n",
    "    low_gain, high_gain = gain_range\n",
    "    gain_value = np.random.uniform(low=low_gain, high=high_gain)\n",
    "    audio = augment_audio_with_sox(path=path, sample_rate=sample_rate,\n",
    "                                   tempo=tempo_value, gain=gain_value)\n",
    "    return audio\n",
    "\n",
    "\n",
    "class SpectrogramParser():\n",
    "    def __init__(self, audio_conf, normalize=False, speed_volume_perturb=False, spec_augment=False):\n",
    "        \"\"\"\n",
    "        Parses audio file into spectrogram with optional normalization and various augmentations\n",
    "        :param audio_conf: Dictionary containing the sample rate, window and the window length/stride in seconds\n",
    "        :param normalize(default False):  Apply standard mean and deviation normalization to audio tensor\n",
    "        :param speed_volume_perturb(default False): Apply random tempo and gain perturbations\n",
    "        :param spec_augment(default False): Apply simple spectral augmentation to mel spectograms\n",
    "        \"\"\"\n",
    "        super(SpectrogramParser, self).__init__()\n",
    "        self.audiotime = 10\n",
    "        self.window_stride = audio_conf['window_stride']\n",
    "        self.window_size = audio_conf['window_size']\n",
    "        self.sample_rate = audio_conf['sample_rate']\n",
    "        self.window = audio_conf['window']\n",
    "        self.normalize = normalize\n",
    "        self.speed_volume_perturb = speed_volume_perturb\n",
    "        self.spec_augment = spec_augment\n",
    "        self.noiseInjector = NoiseInjection(audio_conf['noise_dir'], self.sample_rate,\n",
    "                                            audio_conf['noise_levels']) if audio_conf.get(\n",
    "            'noise_dir') is not None else None\n",
    "        self.noise_prob = audio_conf.get('noise_prob')\n",
    "        \n",
    "\n",
    "    def parse_audio(self, audio_path):\n",
    "        time = 0\n",
    "        if self.speed_volume_perturb:\n",
    "            y = load_randomly_augmented_audio(audio_path, self.sample_rate)\n",
    "        else:\n",
    "            y, time = load_audio(audio_path, self.audiotime)\n",
    "        if self.noiseInjector:\n",
    "            add_noise = np.random.binomial(1, self.noise_prob)\n",
    "            if add_noise:\n",
    "                y = self.noiseInjector.inject_noise(y)\n",
    "        n_fft = int(self.sample_rate * self.window_size)\n",
    "        win_length = n_fft\n",
    "        hop_length = int(self.sample_rate * self.window_stride)\n",
    "        # STFT\n",
    "        D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length,\n",
    "                         win_length=win_length, window=self.window)\n",
    "        spect, phase = librosa.magphase(D)\n",
    "        # S = log(S+1)\n",
    "        spect = np.log1p(spect)\n",
    "        '''\n",
    "        spect = torch.FloatTensor(spect)\n",
    "        if self.normalize:\n",
    "            mean = spect.mean()\n",
    "            std = spect.std()\n",
    "            spect.add_(-mean)\n",
    "            spect.div_(std)\n",
    "\n",
    "        if self.spec_augment:\n",
    "            spect = spec_augment(spect)\n",
    "        '''\n",
    "\n",
    "        return spect, time\n",
    "        \n",
    "    # random cnn\n",
    "    def spectrum2wav(self, spectrum, sr, outfile):\n",
    "        # Return the all-zero vector with the same shape of `a_content`\n",
    "        a = np.exp(spectrum) - 1\n",
    "        p = 2 * np.pi * np.random.random_sample(spectrum.shape) - np.pi\n",
    "        n_fft = int(self.sample_rate * self.window_size)\n",
    "        for i in range(50):\n",
    "            S = a * np.exp(1j * p)\n",
    "            x = librosa.istft(S)\n",
    "            p = np.angle(librosa.stft(x, n_fft))\n",
    "        librosa.output.write_wav(outfile, x, sr)\n",
    "        \n",
    "        \n",
    "class SpectrogramDataset(Dataset, SpectrogramParser):\n",
    "    def __init__(self, audio_conf, pos_dir, neg_dir=None,normalize=False, speed_volume_perturb=False, spec_augment=False):\n",
    "        \"\"\"\n",
    "        Dataset that loads tensors via a csv containing file paths to audio files and transcripts separated by\n",
    "        a comma. Each new line is a different sample. Example below:\n",
    "        /path/to/audio.wav,/path/to/audio.txt\n",
    "        ...\n",
    "        :param audio_conf: Dictionary containing the sample rate, window and the window length/stride in seconds\n",
    "        :param manifest_filepath: Path to manifest csv as describe above\n",
    "        :param labels: String containing all the possible characters to map to\n",
    "        :param normalize: Apply standard mean and deviation normalization to audio tensor\n",
    "        :param speed_volume_perturb(default False): Apply random tempo and gain perturbations\n",
    "        :param spec_augment(default False): Apply simple spectral augmentation to mel spectograms\n",
    "        \"\"\"\n",
    "        self.pos_dir = pos_dir\n",
    "        self.neg_dir = neg_dir\n",
    "        self.pos_files = os.listdir(pos_dir)\n",
    "        if self.neg_dir:\n",
    "            self.neg_files = os.listdir(neg_dir)\n",
    "            self.size = min(len(self.pos_files),len(self.neg_files))\n",
    "        else:\n",
    "            self.neg_files = os.listdir(pos_dir)\n",
    "            self.size = len(self.pos_files)\n",
    "        super(SpectrogramDataset, self).__init__(audio_conf, normalize, speed_volume_perturb, spec_augment)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pos_file = path.join(self.pos_dir, self.pos_files[index])\n",
    "        pos_sample = np.load(pos_file)\n",
    "        if self.neg_dir:\n",
    "            neg_file = path.join(self.neg_dir, self.neg_files[index])\n",
    "            neg_sample = np.load(neg_file)\n",
    "        else:\n",
    "            neg_sample = pos_sample\n",
    "        return pos_sample, neg_sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def shuffle(self):\n",
    "        random.shuffle(self.pos_files)\n",
    "        if self.neg_dir:\n",
    "            random.shuffle(self.neg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-20f4b608ed27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_{:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectrum2wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mspecfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_{:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-353d5ce4b177>\u001b[0m in \u001b[0;36mspectrum2wav\u001b[0;34m(self, spectrum, sr, outfile)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1j\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mistft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36mstft\u001b[0;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode)\u001b[0m\n\u001b[1;32m    238\u001b[0m         stft_matrix[:, bl_s:bl_t] = fft.rfft(fft_window *\n\u001b[1;32m    239\u001b[0m                                              \u001b[0my_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbl_s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbl_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                                              axis=0)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstft_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/mkl_fft/_numpy_fft.py\u001b[0m in \u001b[0;36mrfft\u001b[0;34m(a, n, axis, norm)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmkl_fft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfft_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0munitary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "speed_volume_perturb=False\n",
    "spec_augment=False\n",
    "sr = 16000\n",
    "audio_config = dict(sample_rate=sr,\n",
    "                          window_size=.02,\n",
    "                          window_stride=0.01,\n",
    "                          window='hamming',\n",
    "                          noise_dir=None,\n",
    "                          noise_prob=0.4,\n",
    "                          noise_levels=(0.0, 0.5))\n",
    "directory = '../Data/Hip-Hop/'\n",
    "out_dir = '../Output'\n",
    "pos_dir = '../Data/spectrogram_pos'\n",
    "if not path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "if not path.exists(pos_dir):\n",
    "    os.mkdir(pos_dir)\n",
    "sp = SpectrogramParser(audio_config)\n",
    "index = 0\n",
    "for file in listdir(directory):\n",
    "    filepath = path.join(directory, file)\n",
    "    for i in range(5):\n",
    "        spect,time = sp.parse_audio(filepath)\n",
    "        name, wav = file.split('.')\n",
    "        outfile = path.join(out_dir,name+'_{:.2f}'.format(time)+'.'+wav)\n",
    "        sp.spectrum2wav(spect, sr, outfile)\n",
    "        specfile = path.join(pos_dir, str(index)+'_'+name+'_{:.2f}'.format(time))\n",
    "        np.save(specfile,spect)\n",
    "        index +=1\n",
    "# 16000 465984\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataset = SpectrogramDataset(audio_conf=audio_config,\n",
    "                                   pos_dir=pos_dir,\n",
    "                                   neg_dir=None,\n",
    "                                   normalize=False,\n",
    "                                   speed_volume_perturb=speed_volume_perturb,\n",
    "                                   spec_augment=spec_augment)\n",
    "dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, sampler=None,\n",
    "           batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "           pin_memory=False, drop_last=False, timeout=0,\n",
    "           worker_init_fn=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3482, 0.0958, 0.2982, 0.2716, 0.2555]) torch.Size([1, 161, 1001])\n",
      "tensor([0.9691, 1.0809, 0.9197, 0.3269, 1.3005]) torch.Size([1, 161, 1001])\n",
      "tensor([0.4198, 0.3222, 0.5095, 0.6178, 1.2627]) torch.Size([1, 161, 1001])\n",
      "tensor([2.4724, 2.7397, 2.7526, 2.7633, 2.8971]) torch.Size([1, 161, 1001])\n",
      "tensor([1.8857, 1.9384, 1.8734, 2.3957, 2.8956]) torch.Size([1, 161, 1001])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    for i, (data) in enumerate(dataloader):\n",
    "        pos_sample, neg_sample = data\n",
    "        print(pos_sample[0][0][:5],pos_sample.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
